import asyncio
import json
from typing import Any, Callable, List, Optional, Union

from pydantic import Field

from open_manus.app.agent.react import ReActAgent
from open_manus.app.exceptions import TokenLimitExceeded
from open_manus.app.logger import logger
from open_manus.app.prompt.toolcall import NEXT_STEP_PROMPT, SYSTEM_PROMPT
# -----------------------------------------------------------------------------
# æ–°å¢žï¼šå¼•å…¥ Role ä»¥ä¾¿åŽé¢ä¿®æ”¹ memory ä¸­çš„ assistant æ¶ˆæ¯
# -----------------------------------------------------------------------------
from open_manus.app.schema import (
    TOOL_CHOICE_TYPE,
    AgentState,
    Message,
    ToolCall,
    ToolChoice,
    Role,           # â˜… æ–°å¢ž
)
from open_manus.app.tool import CreateChatCompletion, Terminate, ToolCollection

TOOL_CALL_REQUIRED = "Tool calls required but none provided"


class ToolCallAgent(ReActAgent):
    """Agent that can reason with LLM, invoke tools, and handle their outputs."""

    # -------------------------------------------------------------------------
    # åŸºæœ¬å±žæ€§
    # -------------------------------------------------------------------------
    name: str = "toolcall"
    description: str = "an agent that can execute tool calls."

    system_prompt: str = SYSTEM_PROMPT
    next_step_prompt: str = NEXT_STEP_PROMPT

    available_tools: ToolCollection = ToolCollection(
        CreateChatCompletion(), Terminate()
    )
    tool_choices: TOOL_CHOICE_TYPE = ToolChoice.AUTO  # type: ignore
    special_tool_names: List[str] = Field(default_factory=lambda: [Terminate().name])

    tool_calls: List[ToolCall] = Field(default_factory=list)
    _current_base64_image: Optional[str] = None

    max_steps: int = 30
    max_observe: Optional[Union[int, bool]] = None

    # è¿›åº¦å›žè°ƒï¼ˆä¾›å¤–éƒ¨ UI å®žæ—¶å±•ç¤ºï¼‰
    _progress_callback: Optional[Callable[[str], None]] = None

    # -------------------------------------------------------------------------
    # è¿›åº¦ä¸ŠæŠ¥è¾…åŠ©
    # -------------------------------------------------------------------------
    def set_progress_callback(self, callback: Callable[[str], None]):
        """å…è®¸ UI ä¼ å…¥è¿›åº¦å›žè°ƒå‡½æ•°"""
        self._progress_callback = callback

    async def report_progress(self, tool_name: str, progress_msg: str):
        """åœ¨å·¥å…·æ‰§è¡Œè¿‡ç¨‹ä¸­ä¸ŠæŠ¥è¿›åº¦ï¼ˆå†™æ—¥å¿—å¹¶å›žè°ƒ UIï¼‰"""
        progress_message = f"[Progress - {tool_name}]: {progress_msg}"
        logger.info(progress_message)

        if self._progress_callback:
            self._progress_callback(progress_message)

        # ä¸æŠŠè¿›åº¦ä¿¡æ¯å†™å…¥ memoryï¼Œé¿å…å¹²æ‰°åŽç»­æ¶ˆæ¯é…å¯¹
        return progress_message

    # -------------------------------------------------------------------------
    # THINK é˜¶æ®µï¼šå†³å®šæ˜¯å¦/å¦‚ä½•è°ƒç”¨å·¥å…·
    # -------------------------------------------------------------------------
    async def think(self) -> bool:
        """Ask the LLM what to do next (possibly create tool calls)."""
        # ï¼ˆ1ï¼‰æŠŠ next_step_prompt æ³¨å…¥ä¸º user æ¶ˆæ¯ï¼Œç»™ LLM æ›´å¤šä¸Šä¸‹æ–‡
        if self.next_step_prompt:
            self.messages += [Message.user_message(self.next_step_prompt)]

        # ï¼ˆ2ï¼‰è¯·æ±‚ LLMï¼Œæºå¸¦å¯ç”¨å·¥å…·ã€tool_choice
        try:
            response = await self.llm.ask_tool(
                messages=self.messages,
                system_msgs=([Message.system_message(self.system_prompt)]
                             if self.system_prompt else None),
                tools=self.available_tools.to_params(),
                tool_choice=self.tool_choices,
            )
        except ValueError:
            raise
        except Exception as e:
            # æ•èŽ· RetryError å†…åµŒçš„ TokenLimitExceeded
            if hasattr(e, "__cause__") and isinstance(e.__cause__, TokenLimitExceeded):
                token_limit_error = e.__cause__
                logger.error(f"ðŸš¨ Token limit error: {token_limit_error}")
                self.memory.add_message(
                    Message.assistant_message(
                        f"Maximum token limit reached: {token_limit_error}"
                    )
                )
                self.state = AgentState.FINISHED
                return False
            raise

        # ï¼ˆ3ï¼‰è§£æž LLM è¿”å›ž
        self.tool_calls = tool_calls = response.tool_calls or []
        content = response.content or ""

        # æ—¥å¿—
        logger.info(f"âœ¨ {self.name}'s thoughts: {content}")
        logger.info(f"ðŸ› ï¸ {self.name} selected {len(tool_calls)} tools to use")
        if tool_calls:
            logger.info(
                f"ðŸ§° Tools being prepared: {[call.function.name for call in tool_calls]}"
            )
            logger.info(f"ðŸ”§ Tool arguments: {tool_calls[0].function.arguments}")

        # ï¼ˆ4ï¼‰æ ¹æ® tool_choice ç­–ç•¥å†³å®šä¸‹ä¸€æ­¥
        assistant_msg = (
            Message.from_tool_calls(content=content, tool_calls=tool_calls)
            if tool_calls
            else Message.assistant_message(content)
        )
        self.memory.add_message(assistant_msg)

        if self.tool_choices == ToolChoice.NONE:
            return bool(content)

        if self.tool_choices == ToolChoice.REQUIRED and not tool_calls:
            return True  # äº¤ç»™ act() æŠ›é”™

        if self.tool_choices == ToolChoice.AUTO and not tool_calls:
            return bool(content)

        return bool(tool_calls)

    # -------------------------------------------------------------------------
    # æ‘˜è¦å•ä¸ªå·¥å…·è¿è¡Œç»“æžœ
    # -------------------------------------------------------------------------
    async def summarize_tool_results(self, tool_name: str, result: str) -> str:
        summary_prompt = (
            f"You executed the tool '{tool_name}' and got the result below:\n\n"
            f"{result}\n\n"
            "Give a concise, userâ€‘friendly summary of what this result means."
        )

        response = await self.llm.ask(
            messages=[Message.user_message(summary_prompt)],
            system_msgs=[Message.system_message(
                "Summarize the tool execution result concisely."
            )],
            stream=False,
        )
        self.memory.add_message(Message.assistant_message(response))
        return response

    # -------------------------------------------------------------------------
    # ACT é˜¶æ®µï¼šçœŸæ­£è°ƒç”¨å·¥å…· & å¤„ç†ç»“æžœ
    # -------------------------------------------------------------------------
    async def act(self) -> str:
        # ---------- 0. æ²¡æœ‰ tool_call ----------
        if not self.tool_calls:
            if self.tool_choices == ToolChoice.REQUIRED:
                raise ValueError(TOOL_CALL_REQUIRED)
            return self.messages[-1].content or "No content or commands to execute"

        results: List[str] = []
        summaries: List[str] = []

        # ---------- 1. é€ä¸ªæ‰§è¡Œå·¥å…· ----------
        for command in self.tool_calls:
            self._current_base64_image = None
            await self.report_progress(command.function.name, "Starting tool execution")

            result = await self.execute_tool(command)
            if self.max_observe:
                result = result[: self.max_observe]

            logger.info(
                f"ðŸŽ¯ Tool '{command.function.name}' completed. Result: {result}"
            )

            # æŠŠ tool æ¶ˆæ¯å†™è¿› memory
            self.memory.add_message(
                Message.tool_message(
                    content=result,
                    tool_call_id=command.id,
                    name=command.function.name,
                    base64_image=self._current_base64_image,
                )
            )
            results.append(result)

            await self.report_progress(
                command.function.name, "Tool execution completed"
            )

            # å¦‚éžç‰¹æ®Šå·¥å…·ï¼Œç”Ÿæˆä¸€æ®µæ‘˜è¦
            if not self._is_special_tool(command.function.name):
                await self.report_progress(command.function.name, "Generating summary")
                summaries.append(
                    await self.summarize_tool_results(command.function.name, result)
                )

        # ---------- 2. â˜… å…³é”®ä¿®å¤ï¼šç§»é™¤ä¸Šä¸€æ¡å¸¦ tool_calls çš„ assistant æ ‡è®° ----------
        # for msg in reversed(self.memory.messages):
        #     if msg.role == Role.ASSISTANT and msg.tool_calls:
        #         msg.tool_calls = None  # â˜… åˆ æŽ‰å­—æ®µï¼Œé…å¯¹å®Œæˆ
        #         break

        # ---------- 3. è¿”å›ž ----------
        return "\n\n".join(summaries) if summaries else "\n\n".join(results)

    # -------------------------------------------------------------------------
    # å•ä¸ªå·¥å…·æ‰§è¡Œ
    # -------------------------------------------------------------------------
    async def execute_tool(self, command: ToolCall) -> str:
        if not command or not command.function or not command.function.name:
            return "Error: Invalid command format"

        name = command.function.name
        if name not in self.available_tools.tool_map:
            return f"Error: Unknown tool '{name}'"

        try:
            args = json.loads(command.function.arguments or "{}")

            await self.report_progress(name, f"Executing with arguments: {args}")

            tool = self.available_tools.tool_map[name]

            # è‹¥å·¥å…·è‡ªèº«æ”¯æŒ progress_callbackï¼Œåˆ™æ³¨å…¥
            if hasattr(tool, "set_progress_callback"):
                tool.set_progress_callback(
                    lambda m: asyncio.create_task(self.report_progress(name, m))
                )

            logger.info(f"ðŸ”§ Activating tool: '{name}'...")
            result = await self.available_tools.execute(name=name, tool_input=args)

            # å¤„ç†ç‰¹æ®Šå·¥å…·
            await self._handle_special_tool(name=name, result=result)

            # å¦‚è¿”å›žå¯¹è±¡å¸¦ base64_imageï¼Œåˆ™ä¿å­˜
            if getattr(result, "base64_image", None):
                self._current_base64_image = result.base64_image

            observation = (
                f"Observed output of cmd `{name}` executed:\n{result}"
                if result else f"Cmd `{name}` completed with no output"
            )
            return observation

        except json.JSONDecodeError:
            logger.error(f"ðŸ“ Invalid JSON for '{name}': {command.function.arguments}")
            return f"Error: Invalid JSON arguments for '{name}'"
        except Exception as e:
            logger.exception(f"âš ï¸ Tool '{name}' error: {e}")
            return f"Error: Tool '{name}' encountered a problem: {e}"

    # -------------------------------------------------------------------------
    # æœ€ç»ˆæ€»ç»“
    # -------------------------------------------------------------------------
    async def generate_final_summary(self) -> str:
        prompt = (
            "Provide a clear, wellâ€‘formatted report of everything done in this session:\n"
            "1. Overview of accomplishments\n"
            "2. Tools used & their purpose\n"
            "3. Key findings\n"
            "4. Conclusions / recommendations"
        )
        self.memory.add_message(Message.user_message(prompt))
        summary = await self.llm.ask(
            messages=self.memory.messages,
            system_msgs=[Message.system_message(
                "Create a professional final report."
            )],
            stream=False,
        )
        self.memory.add_message(Message.assistant_message(summary))
        return summary

    # -------------------------------------------------------------------------
    # ç‰¹æ®Šå·¥å…·å¤„ç† / æ”¶å°¾
    # -------------------------------------------------------------------------
    async def _handle_special_tool(self, name: str, result: Any, **kwargs):
        if not self._is_special_tool(name):
            return
        if self._should_finish_execution(name=name, result=result, **kwargs):
            logger.info(f"ðŸ Special tool '{name}' finished the task.")
            self.state = AgentState.FINISHED

    @staticmethod
    def _should_finish_execution(**kwargs) -> bool:
        return True

    def _is_special_tool(self, name: str) -> bool:
        return name.lower() in (n.lower() for n in self.special_tool_names)

    async def cleanup(self):
        logger.info(f"ðŸ§¹ Cleaning up resources for agent '{self.name}'...")
        for tool_name, tool in self.available_tools.tool_map.items():
            if hasattr(tool, "cleanup") and asyncio.iscoroutinefunction(tool.cleanup):
                try:
                    await tool.cleanup()
                except Exception as e:
                    logger.error(f"ðŸš¨ Error cleaning tool '{tool_name}': {e}")
        logger.info(f"âœ¨ Cleanup complete for agent '{self.name}'.")

    # -------------------------------------------------------------------------
    # é¡¶å±‚ runï¼šæ‰§è¡Œ + è‡ªåŠ¨ cleanup + æœ€ç»ˆæ€»ç»“
    # -------------------------------------------------------------------------
    async def run(self, request: Optional[str] = None) -> str:
        try:
            result = await super().run(request)
            if self.state == AgentState.FINISHED:
                try:
                    return await self.generate_final_summary()
                except Exception as e:
                    logger.error(f"Error generating final summary: {e}")
                    return result + "\n\n[Final summary generation failed]"
            return result
        finally:
            await self.cleanup()
